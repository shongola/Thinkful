{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sentiment_labelled_sentences/yelp_labelled.txt\"\n",
    "            )\n",
    "yelp_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "yelp_raw.columns = ['text', 'sentiment']\n",
    "\n",
    "yelp_raw['text'] = yelp_raw['text'].str.replace(',', '')\n",
    "yelp_raw['text'] = yelp_raw['text'].str.replace('.', '')\n",
    "yelp_raw['text'] = yelp_raw['text'].str.replace('!', '')\n",
    "\n",
    "# create sentiment features\n",
    "\n",
    "keywords = ['great', 'best', 'good', 'nice', 'friendly', \"attentive\", \"excellent\", 'amazing', 'delicious', 'wonderful', 'love',\n",
    "           'perfect', 'tasty', 'ambiance', 'attentive', 'absolutely','loved','prompt','beautiful','delight','tender',\n",
    "           'right','fresh','best','fantastic','terrific','fun','flavourful', 'atmosphere',\n",
    "           'clean','inexpensive','outstanding','recommend','favorite','5','better','perfectly','back','awesome',\n",
    "           'filling','thumbs up', 'perfect', 'promptly', 'favourite', 'reasonable', 'quick', 'happy',\n",
    "           'satifying', 'devine','yummy', 'moist', 'flavorful','pleasure','delightful', 'enjoyed', 'highlight']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    yelp_raw[str(key)] = yelp_raw.text.str.contains(' ' + str(key) + ' ', case=False)\n",
    "    \n",
    "yelp_raw['sentiment'] = (yelp_raw['sentiment'] == 1)\n",
    "\n",
    "data = yelp_raw[keywords]\n",
    "target = yelp_raw['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 295\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.7\n",
      "Testing on Sample: 0.705\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 30% Holdout: 0.67\n",
      "Testing on Sample: 0.705\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=20)\n",
    "print('With 30% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 40% Holdout: 0.6625\n",
      "Testing on Sample: 0.705\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.4, random_state=20)\n",
    "print('With 40% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64, 0.68, 0.7 , 0.69, 0.68, 0.68, 0.71, 0.73, 0.66, 0.71])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64, 0.64, 0.66, 0.7 , 0.7 , 0.7 , 0.66, 0.72, 0.66, 0.74, 0.66,\n",
       "       0.7 , 0.76, 0.66, 0.68, 0.78, 0.62, 0.66, 0.72, 0.7 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bnb, data, target, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[471  29]\n",
      " [266 234]]\n",
      "Accuracy Score: 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.94      0.76       500\n",
      "        True       0.89      0.47      0.61       500\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.76      0.70      0.69      1000\n",
      "weighted avg       0.76      0.70      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "actual = yelp_raw['sentiment']\n",
    "predicted = y_pred\n",
    "results = confusion_matrix(actual, predicted)\n",
    "\n",
    "# recall=when its true how often are we predicting true\n",
    "# precision=when it predicts positive, how often is it correct\n",
    "#f1 score - measurement that represents both of predicted and actual. We calculate an F-measure which uses Harmonic Mean in place of Arithmetic Mean as it punishes the extreme values more.\n",
    "# The F-Measure will always be nearer to the smaller value of Precision or Recall.\n",
    "print(results)\n",
    "print('Accuracy Score:',accuracy_score(actual, predicted))\n",
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
